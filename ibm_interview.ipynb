{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5d60f2-ad9f-4ac9-ba32-447421081fa2",
   "metadata": {},
   "source": [
    "# Exercise 2 - Vector Embeddings & Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6634ae5-2008-43e9-9867-9bd6de47e01c",
   "metadata": {},
   "source": [
    "## 2.1 Load and Preview the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cebd9-d91a-44ff-8fa5-c5f579aaf3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV assuming it's in the same directory\n",
    "df = pd.read_csv(\"ex_2_data.csv\")\n",
    "\n",
    "# Preview it\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be32eb-0519-49f9-9c53-be4c603dce74",
   "metadata": {},
   "source": [
    "## 2.2 Generate Embeddings from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600315a-e62c-4154-a6a8-3089db6d47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688dba9-2282-4fe8-9eb6-45008f13695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a compact and effective embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Use the correct column name\n",
    "texts = df[\"paragraph\"].tolist()\n",
    "\n",
    "# Generate embeddings with progress bar\n",
    "embeddings = model.encode(texts, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f0252-5b01-4760-b010-175ca4dcbfb0",
   "metadata": {},
   "source": [
    "## 2.3 Create a Vector DB with Chroma and Index the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514dc38-bb48-4f27-adc1-464b7d683bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import DefaultEmbeddingFunction\n",
    "\n",
    "# Set up in-memory ChromaDB client\n",
    "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "# Create a collection (like a table)\n",
    "collection = client.create_collection(name=\"paragraphs\", get_or_create=True)\n",
    "\n",
    "\n",
    "# Insert the embeddings with their metadata\n",
    "collection.add(\n",
    "    documents=texts,  # original text\n",
    "    embeddings=embeddings,  # generated embeddings\n",
    "    ids=[str(i) for i in df[\"id\"].tolist()],  # use the 'id' column\n",
    "    metadatas=df[[\"source\", \"category\"]].to_dict(orient=\"records\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8761d2-47c1-4283-9fd3-b14eb0d824fa",
   "metadata": {},
   "source": [
    "## 2.4 Semantic Search: Retrieve Top-5 Similar Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275c339-d25c-4140-9830-a4bbceae3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user query\n",
    "query = \"What is reinforcement learning?\"\n",
    "\n",
    "# Search for the top 5 most similar paragraphs\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "# Display the results with their metadata\n",
    "for i in range(5):\n",
    "    print(f\"\\nüîπ Match {i+1}\")\n",
    "    print(\"Paragraph:\", results[\"documents\"][0][i])\n",
    "    print(\"Source:\", results[\"metadatas\"][0][i][\"source\"])\n",
    "    print(\"Category:\", results[\"metadatas\"][0][i][\"category\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293f53d-b1d9-4478-8c42-a611127843b8",
   "metadata": {},
   "source": [
    "## Business Insights & Client-Facing Recommendations\n",
    "\n",
    "### üîç Key Business Insights:\n",
    "- We successfully built a **semantic search pipeline** using sentence embeddings and ChromaDB.\n",
    "- The system can **identify semantically similar content**, even when wording differs ‚Äî enabling smarter search, FAQ automation, or knowledge base enhancement.\n",
    "- This method scales well for **internal document retrieval**, **customer service automation**, or **R&D content indexing**.\n",
    "\n",
    "### üß† Example Use Cases:\n",
    "- **Customer Support**: Retrieve relevant troubleshooting articles or past tickets based on customer queries.\n",
    "- **Enterprise Knowledge Base**: Let employees find policies or procedures using natural questions.\n",
    "- **R&D and Legal Teams**: Quickly surface patents, papers, or legal precedents semantically related to the topic of interest.\n",
    "\n",
    "---\n",
    "\n",
    "### üß∞ Mapping to IBM Tools & Services:\n",
    "- **IBM watsonx.ai**: Can host and fine-tune foundation models, including MiniLM-style transformers, for vector representation.\n",
    "- **IBM watsonx.data**: Combine structured + unstructured semantic search over hybrid data lakes.\n",
    "- **IBM Cloud Databases for Elasticsearch**: A scalable vector DB alternative to ChromaDB, allowing enterprise-grade search.\n",
    "- **IBM Cloud Pak for Data**: Full AI lifecycle platform where embedding models and search pipelines can be deployed with governance.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ This solution shows how foundational AI components (like embedding models + vector search) can power real-world business tools. It's a modular and explainable approach that can evolve with client needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ab7fd-e119-46ec-a592-eb5044dd74d8",
   "metadata": {},
   "source": [
    "# Exercise 3 - LLM-based Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981e21d-a764-4092-82a1-9b96f5570316",
   "metadata": {},
   "source": [
    "## 3.1 Load the Summaries and Compare with BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6b72f-4016-4a13-80e6-41dd4185a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# Load summaries from the uploaded files\n",
    "with open(\"summary-1-flan-ul2--article1.txt\", \"r\") as f:\n",
    "    reference_summary = f.read()\n",
    "\n",
    "with open(\"summary-2-flan-ul2--article1.txt\", \"r\") as f:\n",
    "    candidate_summary = f.read()\n",
    "\n",
    "# Tokenize the summaries\n",
    "reference_tokens = [reference_summary.split()]\n",
    "candidate_tokens = candidate_summary.split()\n",
    "\n",
    "# Apply smoothing (for shorter summaries)\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "# Compute BLEU score\n",
    "bleu_score = sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothie)\n",
    "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a27b3a-ee89-430a-abb9-c2c5661a7cb5",
   "metadata": {},
   "source": [
    "## BLEU Score Interpretation\n",
    "A BLEU score of 0.0139 is very low.\n",
    "This indicates very limited lexical overlap between the candidate and reference summary.\n",
    "It may suggest different wording or structure, not necessarily poor content ‚Äî especially in summarization where rewording is common.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174774e-36c4-4e2e-ba4a-95e0e1901b5c",
   "metadata": {},
   "source": [
    "## Final Business Insights & IBM Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebf40f-3a1d-4d1d-8414-98e8c4d05daf",
   "metadata": {},
   "source": [
    "## üí° Business Insights & IBM Solutions\n",
    "\n",
    "- The BLEU score shows a significant divergence between the two summaries, likely due to different phrasing or structure.\n",
    "- This underlines a common business challenge: **automated text evaluation needs context-aware metrics**, not just word overlap.\n",
    "- Organizations building summarization or translation tools should adopt **multi-metric evaluation** strategies that balance lexical precision with semantic relevance.\n",
    "\n",
    "### ‚úÖ IBM Tools & Capabilities\n",
    "- Use **IBM watsonx.ai** to compare candidate summaries using semantic similarity metrics (e.g., cosine similarity on embeddings).\n",
    "- Integrate **IBM Watson Natural Language Understanding (NLU)** to assess sentiment, key concepts, and named entities in summaries for deeper insights.\n",
    "- For scalable and compliant NLP pipelines, deploy **IBM Cloud Pak for Data** with integrated governance and automated model lifecycle tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a63382-69b8-4f9e-84f2-c097901a4176",
   "metadata": {},
   "source": [
    "# Exercise 1: Model Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bd12f-64cb-4ad5-b85b-bc026570e90e",
   "metadata": {},
   "source": [
    "## 1.1: Load and Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89904b93-bea4-4f20-894d-ad6d80b0b7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>Nexarion Inc.</td>\n",
       "      <td>We're on the hunt for a talented software engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>Eonix Solutions</td>\n",
       "      <td>About Us: We're a team of innovators and probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>Kaidon Technologies</td>\n",
       "      <td>Job Title: Product Manager\\nLocation: Redmond,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>Lumina Creative</td>\n",
       "      <td>Our company is a dynamic and innovative startu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>Voltara Inc.</td>\n",
       "      <td>Job Summary: We're seeking an electrical engin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  posting_date         company_name  \\\n",
       "0   2024-09-01        Nexarion Inc.   \n",
       "1   2024-08-25      Eonix Solutions   \n",
       "2   2024-09-10  Kaidon Technologies   \n",
       "3   2024-08-30      Lumina Creative   \n",
       "4   2024-09-05         Voltara Inc.   \n",
       "\n",
       "                                     job_description  \n",
       "0  We're on the hunt for a talented software engi...  \n",
       "1  About Us: We're a team of innovators and probl...  \n",
       "2  Job Title: Product Manager\\nLocation: Redmond,...  \n",
       "3  Our company is a dynamic and innovative startu...  \n",
       "4  Job Summary: We're seeking an electrical engin...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the job postings data\n",
    "df = pd.read_csv(\"job_postings.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fcdcd-fc79-40b5-bf23-5079f7453ad3",
   "metadata": {},
   "source": [
    "## 1.2: Prepare Prompt and Hugging Face API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38dbce5-53a4-46d1-a72b-f833386acb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# ‚úÖ Switched to a Hugging Face-hosted model that works\n",
    "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 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\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24f4cc-c78c-4d5c-a574-3f545ad57cd9",
   "metadata": {},
   "source": [
    "## 1.3 Define a prompt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72a44abb-ce92-4172-9919-b6fdf27a9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_info(description):\n",
    "    prompt = f\"\"\"You are an AI assistant. Extract the following information from this job description:\n",
    "- Job Title\n",
    "- Location\n",
    "- Salary Range (if mentioned)\n",
    "\n",
    "Format the output as JSON with keys: \"title\", \"location\", \"salary\".\n",
    "\n",
    "Job Description:\n",
    "\\\"\\\"\\\"\n",
    "{description}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
    "    \n",
    "    # üîç NEW DEBUG BLOCK\n",
    "    print(\"Status code:\", response.status_code)\n",
    "    print(\"Raw response text:\", response.text)\n",
    "\n",
    "    # Safely try to decode JSON\n",
    "    try:\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return {\"error\": \"Invalid JSON\", \"details\": str(e), \"raw\": response.text}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88389338-36fb-4666-adc6-e87fbe71c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 404\n",
      "Raw response text: Not Found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'error': 'Invalid JSON',\n",
       " 'details': 'Expecting value: line 1 column 1 (char 0)',\n",
       " 'raw': 'Not Found'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with one job description\n",
    "extract_job_info(df.loc[0, \"job_description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbb348-9182-4680-b3af-9ef5168713d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
